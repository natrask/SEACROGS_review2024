# SEACROGS_review2024

We have gathered here for convenience slides and the report for the 2024 review of SEA-CROGs. 

# Schedule with links to talks #

- Introductory remarks: George Karniadakis (Brown/PNNL). 15m. - [slides](https://github.com/natrask/SEACROGS_review2024/blob/main/Slides/karniadakis_overview.pptx)
- Operators (50m)
  - Introductory remarks: Panos Stinis (PNNL). 5m. - [slides](https://github.com/natrask/SEACROGS_review2024/blob/main/Slides/stinis_operators.pptx)
  - Amanda Howard (PNNL). 15m. - [slides](link)
  - Vivek Oomen (Brown). 15m. - [slides](https://github.com/natrask/SEACROGS_review2024/blob/main/Slides/vivekoommen_operators.pptx)
  - Yasmin Jalalian (Caltech). 15m. - [slides](https://github.com/natrask/SEACROGS_review2024/blob/main/Slides/jalalian_operators.pptx),[pdf version](https://github.com/natrask/SEACROGS_review2024/blob/main/Slides/jalalian_operators.pdf)
- Graphs (70m)
  - Introductory remarks: Nat Trask (UPenn/SNL). 10m. - [slides](https://github.com/natrask/SEACROGS_review2024/blob/main/Slides/trask_graphs.pptx)
  - Anthony Gruber (SNL). 15m. - [slides](https://github.com/natrask/SEACROGS_review2024/blob/main/Slides/Gruber_SEA-CROGS_2024_review.pptx)
  - Alan John Varghese (Brown). 15m. - [slides](https://github.com/natrask/SEACROGS_review2024/blob/main/Slides/varghese_graphs.pptx)
  - Houman Owhadi (Caltech). 15m. - [slides](https://github.com/natrask/SEACROGS_review2024/blob/main/Slides/owhadi_graphs.pptx)
  - Elise Walker (SNL). 15m - [pre-recorded talk](https://github.com/natrask/SEACROGS_review2024/blob/main/Pre-recorded%20talks/DG2DAG_NovReview_static.mp4), [slides](https://github.com/natrask/SEACROGS_review2024/blob/main/Slides/elisewalker_graphs.pptx)
- Spikes (50m)
  - Introductory remarks: Priya Panda (Yale) 20m. - [slides](link)
  - Qian Zhang (Brown). 15m. - [slides](https://github.com/natrask/SEACROGS_review2024/blob/main/Slides/qianzhang_spikes.pptx)
  - Brad Theilman (SNL). 15m . - [slides](https://github.com/natrask/SEACROGS_review2024/blob/main/Slides/theilman_spikes.pptx)
- Outreach, interactions, and mentorship
  - Eric Cyr (SNL). 15m. - [slides](https://github.com/natrask/SEACROGS_review2024/blob/main/Slides/cyr_integration.pptx)

Total presentation time : 190 minutes
Time for on-the-fly questions: 15 minutes
Total time: 210 minutes

# Report #
The report summarizing all aspects of research and programmatics of the center can be found [here](https://github.com/natrask/SEACROGS_review2024/blob/main/Report/SEA_CROGS2024.pdf).

# Dissemination metrics #
In the prior reporting year, the center has produced **67 journal publications**, **15 conference publications**, **87 invited talks**, **8 open-source software packages**, and **15 minisymposia/workshops**.

## Journal publications

1. Actor, J. A., Gruber, A., Cyr, E. C. & Trask, N. Gaussian Variational Schemes on Bounded and Unbounded Domains. arXiv preprint arXiv:2410.06219 (2024)
2. Actor, J. A., Hu, X., Huang, A., Roberts, S. A. & Trask, N. Data-driven Whitney forms for structure-preserving control volume analysis. Journal of Computational Physics 496, 112520 (2024)
3. Anagnostopoulos, S. J., Toscano, J. D., Stergiopulos, N. & Karniadakis, G. E. Learning in PINNs: Phase transition, total diffusion, and generalization. arXiv preprint arXiv:2403.18494 (2024)
4. Antolik, J. T., Howard, A., Vereda, F., Ionkin, N., Maxey, M. & Harris, D. M. Hydrodynamic irreversibility of non-Brownian suspensions in highly confined duct flow. Journal of Fluid Mechanics 974, A11 (2023)
5. Armstrong, E., Hansen, M. A., Knaus, R. C., Trask, N. A., Hewson, J. C. & Sutherland, J. C. Accurate compression of tabulated chemistry models with partition of unity networks. Combustion Science and Technology 196, 850–867 (2024)
6. Batlle, P., Darcy, M., Hosseini, B. & Owhadi, H. Kernel Methods are Competitive for Operator Learning. Journal of Computational Physics 496, 112549 (2024)
7. Batlle, P., Patil, P., Stanley, M., Owhadi, H. & Kuusela, M. Optimization-based frequentist confidence intervals for functionals in constrained inverse problems: Resolving the Burrus conjecture. arXiv preprint arXiv:2310.02461 (2023)
8. Batlle, P., Chen, Y., Hosseini, B., Owhadi, H. & Stuart, A. M. Error Analysis of Kernel/GP Methods for Nonlinear and Parametric PDEs. arXiv preprint arXiv:2305.04962 (2023) (accepted, Journal of Computational Physics.)
9. Bourdais, T., Batlle, P., Yang, X., Baptista, R., Rouquette, N. & Owhadi, H. Codiscovering graphical structure and functional relationships within data: A Gaussian Process framework for connecting the dots. Proceedings of the National Academy of Sciences 121, e2403449121 (2024)
10. Bourdais, T. & Owhadi, H. Model aggregation: minimizing empirical variance outperforms minimizing empirical error. arXiv preprint arXiv:2409.17267 (2024)
11. Cao, Q., Goswami, S. & Karniadakis, G. E. Laplace neural operator for solving differential equations. Nature Machine Intelligence 6, 631–640 (2024)
12. Cao, Q., Goswami, S., Tripura, T., Chakraborty, S. & Karniadakis, G. E. Deep neural operators can predict the real-time response of floating offshore structures under irregular waves. Computers & Structures 291, 107228 (2024)
13. Chen, P., Meng, T., Zou, Z., Darbon, J. & Karniadakis, G. E. Leveraging Multitime Hamilton–Jacobi PDEs for Certain Scientific Machine Learning Problems. SIAM Journal on Scientific Computing 46, C216–C248 (2024)
14. Chen, P., Darbon, J. & Meng, T. Hopf-type representation formulas and efficient algorithms for certain high-dimensional optimal control problems. Computers & Mathematics with Applications 161, 90–120 (2024)
15. Chen, P., Darbon, J. & Meng, T. Lax-Oleinik-type formulas and efficient algorithms for certain high-dimensional optimal control problems. Communications on Applied Mathematics and Computation, 1–44 (2024)
16. Chen, W., Howard, A. A. & Stinis, P. Self-adaptive weights based on balanced residual decay rate for physics-informed neural networks and deep operator networks. arXiv preprint arXiv:2407.01613 (2024) (under review, Journal of Computational Physics.)
17. Chen, W. & Stinis, P. Feature-adjacent multi-fidelity physics-informed machine learning for partial differential equations. Journal of Computational Physics 498, 112683 (2024)
18. Chen, W., Gao, P. & Stinis, P. Physics-informed machine learning of the correlation functions in bulk fluids. Physics of Fluids 36 (2024)
19. Chen, Y., Owhadi, H. & Schäfer, F. Sparse Cholesky Factorization for Solving Nonlinear PDEs via Gaussian Processes. Mathematics of Computation (2024)
20. Cyr, E. C. A 2-Level Domain Decomposition Preconditioner for KKT Systems with Heat-Equation Constraints in Domain Decomposition Methods in Science and Engineering XXVII (eds Dostál, Z., Kozubek, T., Klawonn, A., Langer, U., Pavarino, L. F., Šístek, J. & Widlund, O. B.) (Springer Nature Switzerland, 2024), 463–470
21. De Florio, M., Kahana, A. & Karniadakis, G. E. Analysis of biologically plausible neuron models for regression with spiking neural networks. arXiv preprint arXiv:2401.00369 (2023)
22. Gao, P., Karniadakis, G. E. & Stinis, P. Multiscale modeling framework of a constrained fluid with complex boundaries using twin neural networks. arXiv preprint arXiv:2408.03263 (2024)
23. Heinlein, A., Howard, A. A., Beecroft, D. & Stinis, P. Multifidelity domain decomposition-based physics-informed neural networks for time-dependent problems. arXiv preprint arXiv:2401.07888 (2024) (to appear.)
24. Howard, A. A., Jacob, B., Murphy, S. H., Heinlein, A. & Stinis, P. Finite basis Kolmogorov-Arnold networks: domain decomposition for data-driven and physics-informed problems. arXiv preprint arXiv:2406.19662 (2024)
25. Howard, A. A., Murphy, S. H., Ahmed, S. E. & Stinis, P. Stacked networks improve physics-informed training: Applications to neural networks and deep operator networks. Foundations of Data Science (2024)
26. Howard, A. A., Dong, J., Patel, R., D’Elia, M., Maxey, M. R. & Stinis, P. Machine learning methods for particle stress development in suspension Poiseuille flows. Rheologica Acta 62, 507–534 (2023)
27. Hu, Z., Shukla, K., Karniadakis, G. E. & Kawaguchi, K. Tackling the curse of dimensionality with physics-informed neural networks. Neural Networks, 106369 (2024)
28. Hu, Z., Shi, Z., Karniadakis, G. E. & Kawaguchi, K. Hutchinson trace estimation for high-dimensional and high-order physics-informed neural networks. Computer Methods in Applied Mechanics and Engineering 424, 116883 (2024)
29. Hu, Z., Yang, Z., Wang, Y., Karniadakis, G. E. & Kawaguchi, K. Bias-variance trade-off in physics-informed neural networks with randomized smoothing for high-dimensional PDEs. arXiv preprint arXiv:2311.15283 (2023)
30. Jiang, S., Actor, J., Roberts, S. & Trask, N. in Numerical Analysis Meets Machine Learning (eds Mishra, S. & Townsend, A.) 469–514 (Elsevier, 2024)
31. Kim, Y., Kahana, A., Yin, R., Li, Y., Stinis, P., Karniadakis, G. E. & Panda, P. Rethinking skip connections in Spiking Neural Networks with Time-To-First-Spike coding. Frontiers in Neuroscience 18, 1346805 (2024)
32. Kim, Y., Li, Y., Moitra, A., Yin, R. & Panda, P. Sharing leaky-integrate-and-fire neurons for memory-efficient spiking neural networks. Frontiers in Neuroscience 17, 1230002 (2023)
33. Kopaničáková, A. & Karniadakis, G. E. Deeponet based preconditioning strategies for solving parametric linear systems of equations. arXiv preprint arXiv:2401.02016 (2024)
34. Kuberry, P., Bochev, P., Koester, J. & Trask, N. A discontinuous piecewise polynomial generalized moving least squares scheme for robust finite element analysis on arbitrary grids. Engineering with Computers, 1–20 (2024)
35. Kumar, V., Goswami, S., Kontolati, K., Shields, M. D. & Karniadakis, G. E. Synergistic Learning with Multi-Task DeepONet for Efficient PDE Problem Solving. arXiv preprint arXiv:2408.02198 (2024)
36. Kumar, V., Gleyzer, L., Kahana, A., Shukla, K. & Karniadakis, G. E. Mycrunchgpt: A llm assisted framework for scientific machine learning. Journal of Machine Learning for Modeling and Computing 4 (2023)
37. Li, Y., Yin, R., Kim, Y. & Panda, P. Efficient human activity recognition with spatio-temporal spiking neural networks. Frontiers in Neuroscience 17, 1233037 (2023)
38. Michałowska, K., Goswami, S., Karniadakis, G. E. & Riemer-Sørensen, S. Neural operator learning for long-time integration in dynamical systems with recurrent neural networks in 2024 International Joint Conference on Neural Networks (IJCNN) (2024), 1–8
39. Meng, T., Zou, Z., Darbon, J. & Karniadakis, G. E. HJ-sampler: A Bayesian sampler for inverse problems of a stochastic process by leveraging Hamilton-Jacobi PDEs and score-based generative models. arXiv preprint arXiv:2409.09614 (2024)
40. Moore, N. S., Cyr, E. C., Ohm, P., Siefert, C. M. & Tuminaro, R. S. Graph neural networks and applied linear algebra. SIAM Review (2025) (accepted, to appear).
41. Ovadia, O., Kahana, A., Stinis, P., Turkel, E., Givoli, D. & Karniadakis, G. E. Vito: Vision transformer-operator. Computer Methods in Applied Mechanics and Engineering 428, 117109 (2024)
42. Ovadia, O., Turkel, E., Kahana, A. & Karniadakis, G. E. Ditto: Diffusion-inspired temporal transformer operator. arXiv preprint arXiv:2307.09072 (2023)
43. Owhadi, H. Gaussian process hydrodynamics. Applied Mathematics and Mechanics (English Edition) (2023)
44. Qadeer, S., Engel, A., Howard, A., Tsou, A., Vargas, M., Stinis, P. & Chiang, T. Efficient kernel surrogates for neural network-based regression. arXiv preprint arXiv:2310. 18612 (2023)
45. Sanderse, B., Stinis, P., Maulik, R. & Ahmed, S. E. Scientific machine learning for closure models in multiscale problems: A review. arXiv preprint arXiv:2403.02913 (2024)
46. Schäfer, F. & Owhadi, H. Sparse recovery of elliptic solvers from matrix-vector products. SIAM Journal on Scientific Computing 46, A998–A1025 (2024)
47. Sentz, P., Beckwith, K., Cyr, E. C., Olson, L. N. & Patel, R. Reduced Basis Approximations of Parameterized Dynamical Partial Differential Equations via Neural Networks. Foundations of Data Science (2024) (accepted)
48. Shekarpaz, S., Zeng, F. & Karniadakis, G. Splitting physics-informed neural networks for inferring the dynamics of integer-and fractional-order neuron models. arXiv preprint arXiv:2304.13205 (2023)
49. Shukla, K., Zou, Z., Chan, C. H., Pandey, A., Wang, Z. & Karniadakis, G. E. NeuroSEM: A hybrid framework for simulating multiphysics problems by coupling PINNs and spectral elements. arXiv preprint arXiv:2407.21217 (2024)
50. Toscano, J. D., Käufer, T., Maxey, M., Cierpka, C. & Karniadakis, G. E. Inferring turbulent velocity and temperature fields and their statistics from Lagrangian velocity measurements using physics-informed Kolmogorov-Arnold Networks. arXiv preprint arXiv:2407.15727 (2024)
51. Trask, N., Martinez, C., Shilt, T., Walker, E., Lee, K., Garland, A., Adams, D. P., Curry, J. F., Dugger, M. T., Larson, S. R., et al. Unsupervised physics-informed disentanglement of multimodal materials data. Materials Today (2024)
52. Varghese, A. J., Zhang, Z. & Karniadakis, G. E. SympGNNs: Symplectic Graph Neural Networks for identifying high-dimensional Hamiltonian systems and node classification. arXiv preprint arXiv:2408.16698 (2024)
53. Varghese, A. J., Bora, A., Xu, M. & Karniadakis, G. E. TransformerG2G: Adaptive time-stepping for learning temporal graph embeddings using transformers. Neural Networks 172, 106086 (2024)
54. Verburg, C., Heinlein, A. & Cyr, E. C. DDU-Net: A Domain Decomposition-based CNN for High-Resolution Image Segmentation on Multiple GPUs. arXiv preprint arXiv:2407.21266 (2024) (submitted)
55. Walker, E., Actor, J. A., Martinez, C. & Trask, N. Causal disentanglement of multimodal data. Frontiers in Mechanical Engineering (2023) (accepted)
56. Walker, E., Trask, N., Martinez, C., Lee, K., Actor, J. A., Saha, S., Shilt, T., Vizoso, D., Dingreville, R. & Boyce, B. L. Unsupervised physics-informed disentanglement of multimodal data. Foundations of Data Science (2024)
57. Wu, X., Trask, N. & Chan, J. Entropy stable discontinuous Galerkin methods for the shallow water equations with subcell positivity preservation. Numerical Methods for Partial Differential Equations, e23129 (2024)
58. Yang, L., Sun, X., Hamzi, B., Owhadi, H. & Xie, N. Learning Dynamical Systems from Data: A Simple Cross-Validation Perspective, Part V: Sparse Kernel Flows for 132 Chaotic Dynamical Systems. arXiv preprint arXiv:2301.10321 (2023)
59. Yang, X. & Owhadi, H. A Mini-Batch Method for Solving Nonlinear PDEs with Gaussian Processes. arXiv preprint arXiv:2306.00307 (2023)
60. Yin, R., Kim, Y., Li, Y., Moitra, A., Satpute, N., Hambitzer, A. & Panda, P. Workload-balanced pruning for sparse spiking neural networks. IEEE Transactions on Emerging Topics in Computational Intelligence (2024)
61. Zhang, E., Kahana, A., Turkel, E., Ranade, R., Pathak, J. & Karniadakis, G. E. A hybrid iterative numerical transferable solver (HINTS) for PDEs based on deep operator network and relaxation methods. arXiv preprint arXiv:2208.13273 (2022)
62. Zhang, Q., Kahana, A., Karniadakis, G. E. & Stinis, P. Sms: Spiking marching scheme for efficient long time integration of differential equations. Journal of Computational Physics 516, 113363 (2024)
63. Zhang, Z., Zou, Z., Kuhl, E. & Karniadakis, G. E. Discovering a reaction–diffusion model for Alzheimer’s disease by combining PINNs with symbolic regression. Computer Methods in Applied Mechanics and Engineering 419, 116647 (2024)
64. Zhuang, Q., Yao, C. Z., Zhang, Z. & Karniadakis, G. E. Two-scale Neural Networks for Partial Differential Equations with Small Parameters. arXiv preprint arXiv:2402.17232 (2024)
65. Zou, Z., Kahana, A., Zhang, E., Turkel, E., Ranade, R., Pathak, J. & Karniadakis, G. E. Large scale scattering using fast solvers based on neural operators. arXiv preprint arXiv:2405.12380 (2024)
66. Zou, Z., Meng, X. & Karniadakis, G. E. Correcting model misspecification in physics-informed neural networks (PINNs). Journal of Computational Physics 505, 112918 (2024)
67. Zou, Z., Meng, T., Chen, P., Darbon, J. & Karniadakis, G. E. Leveraging viscous Hamilton–Jacobi PDEs for uncertainty quantification in scientific machine learning. SIAM/ASA Journal on Uncertainty Quantification 12, 1165–1191 (2024)

## Conference Publications

1. Bhattacharjee, A., Moitra, A., Kim, Y., Venkatesha, Y. & Panda, P. Examining the role and limits of batchnorm optimization to mitigate diverse hardware-noise in in-memory computing. *Proceedings of the Great Lakes Symposium on VLSI 2023* (2023), 619–624.
2. Bhattacharjee, A., Yin, R., Moitra, A. & Panda, P. Are SNNs Truly Energy-efficient?—A Hardware Perspective. *ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)* (2024), 13311–13315.
3. Choi, J., Wi, H., Kim, J., Shin, Y., Lee, K., Trask, N. & Park, N. Graph Convolutions Enrich the Self-Attention in Transformers!. arXiv preprint arXiv:2312.04234 (2023).
4. Chen, P., Meng, T., Zou, Z., Darbon, J. & Karniadakis, G. E. Leveraging Hamilton-Jacobi PDEs with time-dependent Hamiltonians for continual scientific machine learning. *6th Annual Learning for Dynamics & Control Conference* (2024), 1–12.
5. Galanti, T., Xu, M., Galanti, L. & Poggio, T. Norm-based Generalization Bounds for Compositionally Sparse Neural Networks. *Advances in Neural Information Processing Systems 36* (2024).
6. Gruber, A., Lee, K., Lim, H., Park, N. & Trask, N. Efficiently Parameterized Neural Metriplectic Systems. arXiv preprint arXiv:2405.16305 (2024).
7. Gruber, A., Lee, K. & Trask, N. Reversible and irreversible bracket-based dynamics for deep graph neural networks. *Advances in Neural Information Processing Systems 36* (2024).
8. Howard, A. A., Qadeer, S., Engel, A. W., Tsou, A., Vargas, M., Chiang, T. & Stinis, P. The conjugate kernel for efficient training of physics-informed deep operator networks. *ICLR 2024 Workshop on AI4DifferentialEquations In Science* (2024).
9. Lee, D., Yin, R., Kim, Y., Moitra, A., Li, Y. & Panda, P. TT-SNN: Tensor Train Decomposition for Efficient Spiking Neural Network Training. *2024 Design, Automation & Test in Europe Conference & Exhibition (DATE)* (2024), 1–6.
10. Li, Y., Geller, T., Kim, Y. & Panda, P. Seenn: Towards temporal spiking early exit neural networks. *Advances in Neural Information Processing Systems 36* (2024).
11. Moitra, A., Yin, R. & Panda, P. Energy-efficient Hardware Design for Spiking Neural Networks. *2023 57th Asilomar Conference on Signals, Systems, and Computers* (2023), 543–544.
12. Moitra, A., Yin, R. & Panda, P. Hardware Accelerators for Spiking Neural Networks for Energy-Efficient Edge Computing. *Proceedings of the Great Lakes Symposium on VLSI 2023* (2023), 137–138.
13. Oommen, V., Bora, A., Zhang, Z. & Karniadakis, G. E. Integrating Neural Operators with Diffusion Models Improves Spectral Representation in Turbulence Modeling. arXiv preprint arXiv:2409.08477 (2024).
14. Theilman, B. H., Zhang, Q., Kahana, A., Cyr, E. C., Trask, N., Aimone, J. B. & Karniadakis, G. E. Spiking Physics-Informed Neural Networks on Loihi 2. *2024 Neuro Inspired Computational Elements Conference (NICE)* (2024), 1–6.
15. Yin, R., Li, Y., Moitra, A. & Panda, P. MINT: Multiplier-less INTeger Quantization for Energy Efficient Spiking Neural Networks. *2024 29th Asia and South Pacific Design Automation Conference (ASP-DAC)* (2024), 830–835.

## Presentations

1. **Actor, J. A.** “Exterior Calculus in Machine Learned Models”. ICME Seminar at Stanford University, Palo Alto, CA. January 2024.
2. **Actor, J. A.** “Exterior Calculus for Machine Learned Models”. Applied Mathematics Seminar Series at University of New Mexico, Albuquerque, NM. September 2024.
3. **Actor, J. A.** “Structure-Preserving Machine Learning via Whitney Forms”. UTEP S. Scott Collis Advanced Modeling and Simulations Seminar, El Paso, TX. October 2023.
4. **Batlle, Pau.** “Frequentist Confidence Intervals: Refuting the Burrus Conjecture”, Digital Twins for Inverse Problems in Earth Science, Marseille, France. July 2024.
5. **Batlle, Pau.** “Transparent and Well-Calibrated Uncertainty Quantification for Ill-Posed Inverse Problems”, Center for Advanced Systems Understanding (CASUS) Seminar, Görlitz, Germany. December 2023.
6. **Batlle, Pau.** “Optimization-Based Frequentist Confidence Intervals for Functionals in Constrained Inverse Problems: Resolving the Burrus Conjecture”, JPL UQ for Remote Sensing Workshop, September 2023.
7. **Batlle, Pau.** “Frequentist Confidence Intervals: Refuting the Burrus Conjecture”, NASA JPL UQ Seminar, September 2023.
8. **Bourdais, Théo.** “Computational Hypergraph Discovery”, One World Seminar Series on the Mathematics of Machine Learning, January 2024.
9. **Bourdais, Théo.** “Computational Hypergraph Discovery”, Digital Twins for Inverse Problems in Earth Science Workshop, Marseille, France. July 2024.
10. **Bourdais, Théo.** “Computational Hypergraph Discovery”, Differential Equations for Data Science (DEDS2024), February 2024.
11. **Cyr, E.C.** Exploiting “time-domain” parallelism to accelerate neural network training and PDE constrained optimization. Bergische Universit:t Wuppertal. August 2024.
12. **Cyr, E.C.** Exploiting “time-domain” parallelism to accelerate neural network training and PDE constrained optimization, Penn State University, State College, PA. April 2024.
13. **Cyr, E.C.** Exploiting “time-domain” parallelism to accelerate neural network training and PDE constrained optimization, University of Pennsylvania, Philadelphia, PA. April 2024.
14. **Cyr, E.C.** Exploiting “time-domain” parallelism to accelerate neural network training, BIRS SciML workshop, Banff, Canada. June 2023.
15. **Cyr, E.C.** Exploiting “time-domain” parallelism to accelerate neural network training and PDE constrained optimization, CCAM seminar at Purdue, West Lafayette, IN. April 2023.
16. **Darcy, Matthieu.** “Kernel Methods and PINNs for Rough Partial Differential Equations”, Digital Twins for Inverse Problems in Earth Sciences, Marseille, France. July 2024.
17. **Darcy, Matthieu.** “Kernel Methods for Rough Partial Differential Equations”, Southern California Applied Mathematics Workshop, San Diego, CA. April 2024.
18. **Darcy, Matthieu.** “Kernel Methods for Operator Learning”, One World Mathematics of Machine Learning Seminar, October 2023.
19. **Darcy, Matthieu.** “Kernel Methods are Competitive for Operator Learning”, Argonne National Lab LANS Seminar, August 2023.
20. **Darcy, Matthieu.** “Kernel Methods are Competitive for Operator Learning”, DataSig Rough Path Interest Group, May 2023.
21. **Darcy, Matthieu.** “Benchmarking Operator Learning with Simple and Interpretable Kernel Methods”, Workshop on Establishing Benchmarks for Data-Driven Modeling of Physical Systems, USC, Los Angeles, CA. April 2023.
22. **Gruber, A.** “Learning metriplectic systems and other bracket-based dynamics”. University of Vienna mathematics seminar, Vienna, Austria. June 2024.
23. **Gruber, A.** “Property-preserving model reduction in bracket-based dynamical systems”. Applied mathematics seminar series at University of New Mexico, Albuquerque, NM. March 2024.
24. **Gruber, A.** “Data-driven dynamical systems with structural guarantees”. S. Scott Collis advanced modeling and simulations virtual seminar series, Rio Grande Consortium for Advanced Research on Exascale Simulation. November 2023.
25. **Gruber, A.** “Data-driven dynamical systems with structural guarantees”. Applied mathematics and machine learning seminar at Texas Tech University, Lubbock, TX. November 2023.
26. **Gruber, A.** “Property-preserving model reduction for conservative and dissipative systems”. Numerical analysis of Galerkin ROMs seminar series , INRIA Bordeaux, France. October 2023.
27. **Howard, A.A.** ”Multifidelity stacking networks for physics-informed training.” Data Sciences for Mesoscale and Macroscale Materials Models, Chicago, Illinois. May 2024.
28. **Howard, A.A.** ”Multifidelity Deep Operator Networks.” Mathematical and Scientific Machine Learning, Providence, RI. June 2023.
29. **Howard, A.A.** ”More of a good thing: multifidelity and stacking networks for physics-informed training.” Portland State University Applied and Computational Mathematics Seminar, Portland, OR. March 2024.
30. **Howard, A.A.** ”More of a good thing: multifidelity and stacking networks for physics-informed training.” Sandia National Laboratory Seminar, Albuquerque, NM. March 2024.
31. **Howard, A.A.** ”Machine learning for Stokes flow: from suspensions to ice sheets.” Advancing fluid and soft-matter dynamics with machine learning and data science, Madison, WI. June 2024.
32. **Howard, A.A.** ”High performance computing for multiphase flows.” Spelman seminar, Atlanta, GA. September 2023.
33. **Jalalian, Y.** “Forecasting Hamiltonian Dynamics with Computational Graph Completion (CGC)”, International Conference of Differential Equations for Data Science (DEDS), February 2023.
34. **Jalalian, Y.** “Data-Efficient Kernel Methods for PDE Identification”, International Conference of Differential Equations for Data Science (DEDS), February 2024.
35. **Karniadakis, G. E.** “Interfacing physics-informed neural networks and neural operators for accelerated FEM simulations of multiscale problems”, ANSYS, Boston, MA. September 2023.
36. **Karniadakis, G. E.** “From Physics-Informed Machine Learning to Physics-Informed Machine Intelligence: Quo Vadimus?”, Georgia Tech, Atlanta, GA. October 2023.
37. **Karniadakis, G. E.** “Interfacing physics-informed neural networks and neural operators for accelerating simulations of multiscale problems”, Simulia. December 2023.
38. **Karniadakis, G. E.** “Recent Advances in PINNs and Deep Neural Operators”, Stanford University, Stanford, CA. March 2024.
39. **Karniadakis, G. E.** “Physics-Informed Machine Learning: Blending data and physics for fast predictions”, Intel. February 2024.
40. **Karniadakis, G. E.** “From Physics-Informed Machine Learning to Physics-Informed Machine Intelligence: Quo Vadimus?”, IIT. April 2024.
41. **Karniadakis, G. E.** “Physics-Informed Machine Learning in Engineering and Sciences”, University of Central Florida. May 2024.
42. **Karniadakis, G. E.** “From Physics-Informed Machine Learning to Physics-Informed Machine Intelligence: Quo Vadimus?”, Purdue University. May 2024.
43. **Karniadakis, G. E.** “Hidden Fluid Mechanics: Learning from any (sparse) data”, Society of Engineering Science. August 2024 (GI Taylor Medal).
44. **Karniadakis, G. E.** “Recent Advances in PINNs and Deep Neural Operators”. September 2024.
45. **Lee, Jonghyeon.** “Gaussian Processes and the Cole-Hopf Transformation”, Southern California Applied Mathematics Symposium, San Diego, CA. April 2024.
46. **Owhadi, H.** “Solving/learning PDEs with GPs and Gaussian Process Hydrodynamics”, International Conference on New Trends of Computational and Data Sciences, Caltech, Pasadena, CA. December 2022.
47. **Owhadi, H.** “Solving/learning PDEs with GPs and Computational Graph Completion”, AI for Science Workshop, Caltech, Pasadena, CA. February 2023.
48. **Owhadi, H.** “Solving/learning PDEs with GPs and Computational Graph Completion”, Differential Equations for Data Science (DEDS2023), February 2023.
49. **Owhadi, H.** “Solving/learning PDEs with GPs and Computational Graph Completion”, Data-driven Modeling of Physical Systems, USC, Los Angeles, CA. April 2023.
50. **Owhadi, H.** “Kernel Mode Decomposition”, MaSAG Conference, Rome, Italy. May 2023.
51. **Owhadi, H.** “Solving/learning PDEs with GPs and Computational Graph Completion”, Inaugural CAMDA Conference, College Station, TX. May 2023.
52. **Owhadi, H.** “Kernel Mode Decomposition”, ECCOMAS-IACM Thematic Conference on Emerging Technologies in Computational Science for Industry, Sicily, Italy. May 2023.
53. **Owhadi, H.** “Computational Hypergraph Discovery and Completion”, ICERM Workshop: Mathematical and Scientific Machine Learning, Providence, RI. June 2023.
54. **Owhadi, H.** “Kernel/GP methods for Surrogate Modeling”, Data Science and Machine Learning Summer School, Emilia Romagna (Italy). June 2023.
55. **Owhadi, H.** “Solving/learning PDEs with GPs and Computational Graph Completion”, Mathematical and Statistical Foundation of Future Data-Driven Engineering, Isaac Newton Institute for Mathematical Sciences, Cambridge (UK). June 2023.
56. **Owhadi, H.** “Solving/learning PDEs with GPs and Computational Graph Completion”, ICIAM 2023: Machine Learning in Infinite Dimensions, Tokyo (Japan). August 2023.
57. **Owhadi, H.** “Computational Hypergraph Discovery”, Boeing Applied Mathematics Colloquium Series, University of Washington, Seattle, WA. November 2023.
58. **Owhadi, H.** “Computational Hypergraph Discovery”, International Workshop on Multiscale Model Reduction and Scientific Machine Learning, Chinese University of Hong Kong (CUHK), Hong Kong (China). December 2023.
59. **Owhadi, H.** “Co-discovering Graphical Structures and Functional Relationships Within Data: a Gaussian Process framework for Connecting the Dots”, SIAM UQ24, (Plenary). February 2024.
60. **Owhadi, H.** “Overview of Gaussian Process Techniques for Bridging Scales through Applications to Fluid Dynamics, Rough PDEs, Arbitrary Nonlinear PDEs, and Finding Functional Dependencies and Graphical Structures Within Data”, Workshop on Scale Bridging in Numerical Simulation, LANL, Los Alamos, NM. April 2024.
61. **Owhadi, H.** “A GP/Kernel Perspective on Digital Twins”, Digital Twins for Inverse Problems in Earth Science, CIRM, Marseille, France. July 2024.
62. **Owhadi, H.** “Overview of Gaussian Process Techniques for Bridging Scales through Applications to Fluid Dynamics, Rough PDEs, Arbitrary Nonlinear PDEs, and Finding Functional Dependencies and Graphical Structures Within Data”, Workshop on Statistical Aspects of Non-Linear Inverse Problems, Cambridge (UK). September 2024.
63. **Owhadi, H.** “Overview of Gaussian Process Techniques for Bridging Scales through Applications to Fluid Dynamics, Rough PDEs, Arbitrary Nonlinear PDEs, and Finding Functional Dependencies and Graphical Structures Within Data”, Colloquium at CMOR Department, Rice University, Houston, TX. October 2024.
64. **Owhadi, H.** “Overview of Gaussian Process Techniques for Bridging Scales through Applications to Fluid Dynamics, Rough PDEs, Arbitrary Nonlinear PDEs, and Finding Functional Dependencies and Graphical Structures Within Data”, UC Riverside Department of Mechanical Engineering Seminar, Riverside, CA. October 2024.
65. **Owhadi, H.** “Overview of Gaussian Process Techniques for Bridging Scales through Applications to Fluid Dynamics, Rough PDEs, Arbitrary Nonlinear PDEs, and Finding Functional Dependencies and Graphical Structures Within Data”, Yale Foundations of Data Science (FDS) Colloquium, New Haven, CT. October 2024.
66. **Panda, P.** “A Co-Design Approach to Efficient and Deployable In-Memory Computing”. Design Automation Conference, SFO, USA. June 2024.
67. **Panda, P.** “Are SNNs truly efficient?- A Hardware Perspective.” ICASSP, Seoul, S. Korea. April 2024.
68. **Panda, P.** “Neuromorphic Computing for Energy-Efficient Edge Intelligence”, VLSI-DAT, Hsinchu, Taiwan. April 2024.
69. **Panda, P.** “Hardware-Aware Low-Precision Federated Learning”, DATE, Valencia, Spain. March 2024.
70. **Panda, P.** “On-device Intelligence with Spiking Neural Networks”, EE Seminar, Harvard University, Cambridge, MA. March 2024.
71. **Panda, P.** “Energy-Efficient Intelligence with Neuromorphic Computing: From Algorithms to Hardware Design”, ECE Seminar, Duke University. January 2024.
72. **Panda, P.** “Rethinking AI Algorithm and Hardware Design with Neuromorphic Computing”, VLSID Conference, Kolkata, India. January 2024.
73. **Panda, P.** “Rethinking AI Algorithm and Hardware Design with Neuromorphic Computing”, ECE Seminar, UC Santa Barbara, Santa Barbara, CA. October 2023.
74. **Panda, P.** “Edge Intelligence with Neuromorphic Computing: From Algorithms to Hardware Design”, ECE Seminar, UC Berkeley, Berkeley, CA. November 2023.
75. **Panda, P.** “Computational Needs for Lifelong Learning”, DARPA ERI Summit. September 2023.
76. **Propp, A.** “Transfer Learning on Multifidelity Data”, Mathematical and Scientific Machine Learning (MSML), Providence, RI. June 2023.
77. **Stinis P.** “When big neural networks are not enough” University of California Santa Cruz, Applied Mathematics Seminar, Santa Cruz, CA. April 2024.
78. **Stinis, P.** “Multifidelity scientific machine learning” Michigan State University, Applied Mathematics Seminar, East Lansing, Michigan. March 2024.
79. **Stinis, P.** “Multifidelity scientific machine learning” Georgia Institute of Technology, Computational Mathematics Seminar, Atlanta, GA. November 2023.
80. **Stinis, P.** “Machine-learning custom-made basis functions for partial differential equations” University of Arizona, Applied Mathematics Colloquium, Tucson, AZ. March 2023.
81. **Tartakovsky, D.** “Use and Abuse of Machine Learning in Scientific Discovery”, EAISI lecture, Eindhoven Artificial Intelligence Systems Institute, Eindhoven University of Technology, Eindhoven, Netherlands. March 2024.
82. **Tartakovsky, D.** “Use and Abuse of Machine Learning in Scientific Discovery”, Argyris Lecture 2023, University of Stuttgart, Stuttgart, Germany. October 2023. 
83. **Trask, N.** "Structure preserving Whitney forms for digital twins and scientific discovery", Courant Institute Department Seminar 2024.
84. **Trask, N.** "Multi-Modal Data Driven and Physics-Informed Machine Learning with Uncertainty for Materials Applications", SIAM Mathematics of Material Science
85. **Trask, N.** "Structure preserving digital twins", PhysML Workshop, Oslo, Norway. May 2024.
86. **Trask, N.** "A data-driven exterior calculus for probabilistic digital twins" MFEM Webinar Series. Lawrence Livermore National Laboratory. April 2024.
87. **Trask, N.** "A data-driven exterior calculus for probabilistic digital twins" ICERM workshop on Numerical Analysis of Multiphysics Problems. Feb 2024.

## Organized Events

1. **Organized Minisymposium:** Panda, P. “SPIKEs”, ICERM 2023 Meeting on Mathematical and Scientific Machine Learning, Providence, RI. June 2023.
2. **Organized Minisymposium:** Actor, J. A., and Walker, E. A. “Beyond Fingerprinting: AI Approaches to Unearthing Process-Structure-Property Correlations in Additive Manufacturing”, U.S. National Congress on Computational Mechanics, Albuquerque, NM. July 2023.
3. **Organized Tutorial:** Panda, P. “Hardware and Software Co-Design for Edge AI”, Design Automation Conference 2023. San Francisco, CA. July 2023.
4. **Organized Minisymposium:** Howard, A. A., and Stinis, P. “Physics-informed machine learning for multiscale materials and engineering systems”, 2nd IACM Mechanistic Machine Learning and Digital Engineering for Computational Science Engineering and Technology, El Paso, TX. September 2023.
5. **Organized Minisymposium:** Actor, J. A., Walker, E. A., et al. “AI/ML Algorithms for Accelerating Material Discovery, Design, and Manufacturing Processes”, 2nd IACM Mechanistic Machine Learning and Digital Engineering for Computational Science Engineering and Technology, El Paso, TX. September 2023.
6. **Organized Special Session:** Panda, P. “Neuromorphic Computing”, Asilomar Conference on Signals, Systems and Computers 2023. Pacific Grove, CA. October 2023.
7. **Organized Tutorial and Workshop:** Panda, P. and Moitra, A. “Energy-Efficient Intelligence with Neuromorphic Computing: From Algorithms to Hardware Design”. VLSID Conference, Kolkata, India. January 2024.
8. **Organized Workshop:** D’Elia, M. and Karniadakis, G. “The industrialization of Scientific Machine Learning”, ICERM, Providence, RI. March 2024.
9. **Organized Minisymposium:** Cyr, E. C., and Smith, D. “Mathematical Advances in Algorithms Design Enabling Emerging Energy Efficient Computing”, SIAM Annual Meeting, Spokane, WA. July 2024.
10. **Organized Minisymposium:** Howard, A. A., and Stinis, P. “Advances in neural operators and uncertainty quantification for scientific modeling”, SIAM Annual Meeting, Spokane, WA. July 2024.
11. **Organized Minisymposium:** Actor, J. A., Walker, E. A., et al. “Causal Discovery and Graphical Causal Models”, 16th World Congress on Computational Mechanics, Vancouver, British Columbia (Canada). July 2024.
12. **Organized Minisymposium:** Walker, E. A., Actor, J. A., et al. “Machine learning algorithms for accelerating material characterization, discovery, design, and manufacturing processes”, 16th World Congress on Computational Mechanics, Vancouver, British Columbia (Canada). July 2024.
13. **Organized Minisymposium:** Perego, M., Howard, A. A., and Stinis, P. “Advances in neural operators for modeling mechanics applications”, 16th World Congress on Computational Mechanics, Vancouver, British Columbia (Canada). July 2024.
14. **Organized Workshop:** Owhadi, H. “Digital Twins for Inverse Problems in Earth Science”, CIRM, Marseille (France). July 2024.
15. **CMWR Committee:** Tartakovsky, D. The Conference on Computational Methods in Water Resources (CMWR 2024), Tucson, AZ. September 2024. 

## Open Source Software Packages

1. **BracketGraphs:** Code accompanying NeurIPS 2023 paper [31]. Available at [https://github.com/natrask/BracketGraphs](https://github.com/natrask/BracketGraphs).
2. **ComputationalHypergraphDiscovery:** Computational Hypergraph Discovery. Available at [https://github.com/TheoBourdais/ComputationalHypergraphDiscovery](https://github.com/TheoBourdais/ComputationalHypergraphDiscovery).
3. **FBKANs:** Code for implementing finite basis KANs [0]. Available at [https://github.com/pnnl/neuromancer/tree/feature/fbkans/examples/KANs](https://github.com/pnnl/neuromancer/tree/feature/fbkans/examples/KANs).
4. **StackedPINNs:** Code for implementing stacked PINNs [10]. Available at [https://github.com/pnnl/neuromancer/blob/master/examples/PDEs/Part_5_Pendulum_Stacked.ipynb](https://github.com/pnnl/neuromancer/blob/master/examples/PDEs/Part_5_Pendulum_Stacked.ipynb).
5. **MINT:** Code accompanying ASPDAC 2024 paper [47]. Available at [https://github.com/Intelligent-Computing-Lab-Yale/MINT-Quantization](https://github.com/Intelligent-Computing-Lab-Yale/MINT-Quantization).
6. **SEENN:** Code accompanying NeurIPS 2023 paper [45]. Available at [https://github.com/Intelligent-Computing-Lab-Yale/SEENN](https://github.com/Intelligent-Computing-Lab-Yale/SEENN).
7. **TTFS:** Code accompanying Frontiers in Neuroscience 2023 paper [46]. Available at [https://github.com/Intelligent-Computing-Lab-Yale/SkipResConnection](https://github.com/Intelligent-Computing-Lab-Yale/SkipResConnection).
8. **uTicket:** Code accompanying IEEE TETCI 2024 paper [48]. Available at [https://github.com/Intelligent-Computing-Lab-Yale/u-Ticket-Pruning](https://github.com/Intelligent-Computing-Lab-Yale/u-Ticket-Pruning).



